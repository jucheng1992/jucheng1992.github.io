<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Navigation</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="experience.html">Experience</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
</td>
<td id="layout-content">
<p><br /></p>
<h1>Research</h1>
<p>My research mainly focuses on causal inference and machine learning. More specifically:</p>
<ul>
<li><p>Variable and model selection for nuisance parameter (e.g. propensity score) estimation in observational study.</p>
</li>
<li><p>Estimation and inference on large-scale and high-dimensional electronic healthcare databases.</p>
</li>
<li><p>Online and offline ensemble machine learning.</p>
</li>
</ul>
<h1>Other Applied Projects</h1>
<h3>Scene Recognition using Convolutional Neural Network</h3>
<p><img src="figure/280-hw3.png" width="200px" height="128px" alt="alt text" /></p>
<p>In this project, we appled Convolutional Neural Network (CNN) for scene recognition on MIT Place dataset. We investigated GoogLeNet, VGG net and Residual Net to classify the scene images. We achieved top 3 (out of 46 teams, 71 participants) performance in the Berkeley Computer Vision course (CS280) competition with respect to the prediction accuracy. <a href="https://inclass.kaggle.com/c/berkeley-cs280-mini-places-challenge">Link</a></p>
<h3>Prediction of Brain  Responses to Visual Images on fMRI data</h3>
<p><img src="figure/215-final.png" width="200px" height="128px" alt="alt text" /></p>
<p>In this project, we studied on the responses in 20 voxels located in the region of the brain responsible for visual functions. There are 120 observations and each with 10921 features (wavelets). We first applied Sure Independence Screening for dimension reduction. Then we investigated Lasso , L2-boosting , Random Forest , Tree Boosting to predict the brain responds. We also applied Knockoff filter to find the significant coefficients while controling the false discover rate.</p>
<h3>Organ Classification and Sengmentation for Drosophila Embryo Image based on Machine Learning and Conputer Vision Method.</h3>
<p><img src="figure/215-lab4.png" width="200px" height="128px" alt="alt text" /></p>
<p>This project mainly focused on distinguish gut, yolk, and epidermal/mesodermal tissue in embryo images. We constructed features from the raw embryo image based on multiple classical computer vision method (e.g. Histogram oriented gradient feature and Local Binary Pattern) with scikit-image in python, selected features based on variable importance from Random Forest and Tree Boosting.	We studied different machine learning algorithms (Random Forest, Tree boosting, Lasso, SVM) to classify and segment the organ.</p>
<h3>Discover of Subculture in US with Dialectometric Analysis using Unsupervised Learning Method.</h3>
<p><img src="figure/215-lab2.png" width="200px" height="128px" alt="alt text" /></p>
<p>In this project, we investigated unspervised learning to the dialectometric analysis of the Harvard Dialect Survey conducted in 2003. We use Multidimensional Scaling (MDS) to visualize the relationship of the questions and answers in the survey data. Based on Term Frequency-Inverse Document Frequency (TF-IDF) model, we proposed a new distance metric and applied k-medoids model to find out and study the sub-culture in America.</p>
<div id="footer">
<div id="footer-text">
Page generated 2017-02-04 17:03:46 PST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
